{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Turn on Logging\n",
    "import logging\n",
    "logging.basicConfig(format = '%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2017-09-08 09:24:22,018 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/whs/Documents/Fun With ML/Gensim Tutorials'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import pandas as pd\n",
    "import os\n",
    "os.getcwd()\n",
    "#os.chdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in 'documents'\n",
    "\n",
    "raw1 = 'The cute kitten purred and watched the Stark girl.'\n",
    "raw2 = ' After losing interest the cute furry cat purred and meowed.'\n",
    "raw3 = ' Sly yet silent, the cute kitten meowed and she noticed.' \n",
    "raw4 = ' The loud furry dog ran and bit at air.'\n",
    "\n",
    "raw_text = str(raw1 + raw2 + raw3 + raw4)\n",
    "raw_text\n",
    "raw_text2 = str(raw1 + raw4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process text w/ SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize 'en' tokenization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.en import English\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push all documents through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The cute kitten purred and watched the Stark girl. After losing interest the cute furry cat purred and meowed. Sly yet silent, the cute kitten meowed and she noticed. The loud furry dog ran and bit at air."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = nlp(raw_text, parse=True)\n",
    "docs2 = nlp(raw_text2, parse=True)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting Text Analysis Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "The cute kitten purred and watched the Stark girl.\n",
      "After losing interest the cute furry cat purred and meowed.\n",
      "Sly yet silent, the cute kitten meowed and she noticed.\n",
      "The loud furry dog ran and bit at air.\n"
     ]
    }
   ],
   "source": [
    "#Now with our text all spacy tokened, we can do cool stuff\n",
    "#https://github.com/cytora/pycon-nlp-in-10-lines\n",
    "\n",
    "# Get first token of the processed document\n",
    "token = docs[0]\n",
    "print(token)\n",
    "\n",
    "# Print sentences (one sentence per line)\n",
    "for sent in docs.sents:\n",
    "    print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The - DET\n",
      "cute - ADJ\n",
      "kitten - NOUN\n",
      "purred - VERB\n",
      "and - CCONJ\n",
      "watched - VERB\n",
      "the - DET\n",
      "Stark - PROPN\n",
      "girl - NOUN\n",
      ". - PUNCT\n",
      "After - ADP\n",
      "losing - VERB\n",
      "interest - NOUN\n",
      "the - DET\n",
      "cute - ADJ\n"
     ]
    }
   ],
   "source": [
    "# For each token, print corresponding part of speech tag\n",
    "for token in docs[0:15]:\n",
    "    print('{} - {}'.format(token, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stark - PERSON\n",
      "Sly - PERSON\n"
     ]
    }
   ],
   "source": [
    "# Print all named entities with named entity types\n",
    "\n",
    "for ent in docs.ents:\n",
    "    print('{} - {}'.format(ent, ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821555381691\n",
      "0.801685591074\n",
      "0.703533825482\n",
      "0.280267313562\n"
     ]
    }
   ],
   "source": [
    "# For a given document, calculate similarity between 'cat', 'kitten', and 'dog'\n",
    "kitten = docs[2]\n",
    "cat = docs[16]\n",
    "dog = docs[36]\n",
    "yet = docs[22]\n",
    "print(cat.similarity(kitten))\n",
    "print(cat.similarity(dog))\n",
    "print(kitten.similarity(dog))\n",
    "print(yet.similarity(dog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Corpus and Dictionary w/ Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 4 sentences found. Here's a sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The cute kitten purred and watched the Stark girl.',\n",
       " 'After losing interest the cute furry cat purred and meowed.',\n",
       " 'Sly yet silent, the cute kitten meowed and she noticed.',\n",
       " 'The loud furry dog ran and bit at air.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [sentence.orth_ for sentence in docs.sents]\n",
    "print(\"There were {} sentences found. Here's a sample:\".format(len(sentences)))\n",
    "pd.DataFrame(sentences[0:5])\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Each Word by Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cute']\n",
      "['cute', 'kitten']\n",
      "['cute', 'kitten', 'purr']\n",
      "['cute', 'kitten', 'purr', 'watch']\n",
      "['cute', 'kitten', 'purr', 'watch', 'stark']\n",
      "['cute', 'kitten', 'purr', 'watch', 'stark', 'girl']\n",
      "['lose']\n",
      "['lose', 'interest']\n",
      "['lose', 'interest', 'cute']\n",
      "['lose', 'interest', 'cute', 'furry']\n",
      "['lose', 'interest', 'cute', 'furry', 'cat']\n",
      "['lose', 'interest', 'cute', 'furry', 'cat', 'purr']\n",
      "['lose', 'interest', 'cute', 'furry', 'cat', 'purr', 'meow']\n",
      "['sly']\n",
      "['sly', 'silent']\n",
      "['sly', 'silent', 'cute']\n",
      "['sly', 'silent', 'cute', 'kitten']\n",
      "['sly', 'silent', 'cute', 'kitten', 'meow']\n",
      "['sly', 'silent', 'cute', 'kitten', 'meow', 'notice']\n",
      "['loud']\n",
      "['loud', 'furry']\n",
      "['loud', 'furry', 'dog']\n",
      "['loud', 'furry', 'dog', 'run']\n",
      "['loud', 'furry', 'dog', 'run', 'bit']\n",
      "['loud', 'furry', 'dog', 'run', 'bit', 'air']\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing Each Word\n",
    "texts, article = [], []\n",
    "for w in docs:\n",
    "    # if it's not a stop word or punctuation mark, add it to our article!\n",
    "    if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n",
    "        # we add the lematized version of the word\n",
    "        article.append(w.lemma_)\n",
    "        print(article)\n",
    "        #texts.append(article)\n",
    "    # if it's a new line, it means we're onto our next document\n",
    "    if w.tag_ == '.' :\n",
    "        texts.append(article)\n",
    "        #print(article) #Print out each word to test\n",
    "        article = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cute', 'kitten', 'purr', 'watch', 'stark', 'girl'],\n",
       " ['lose', 'interest', 'cute', 'furry', 'cat', 'purr', 'meow'],\n",
       " ['sly', 'silent', 'cute', 'kitten', 'meow', 'notice'],\n",
       " ['loud', 'furry', 'dog', 'run', 'bit', 'air']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine all lines into one list\n",
    "#for sentances in document for sentences \n",
    "texts_single = [item for sublist in texts for item in sublist]\n",
    "\n",
    "#This list comprehension is doing the same as:\n",
    "#for sublist in texts:\n",
    "#    for item in sublist:\n",
    "#        flat_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cute', 'kitten', 'purr', 'watch', 'stark']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_single[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-08 09:24:27,578 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-09-08 09:24:27,580 : INFO : built Dictionary(19 unique tokens: ['cute', 'kitten', 'purr', 'watch', 'stark']...) from 4 documents (total 25 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cute': 0, 'kitten': 1, 'purr': 2, 'watch': 3, 'stark': 4, 'girl': 5, 'lose': 6, 'interest': 7, 'furry': 8, 'cat': 9, 'meow': 10, 'sly': 11, 'silent': 12, 'notice': 13, 'loud': 14, 'dog': 15, 'run': 16, 'bit': 17, 'air': 18}\n",
      "Dictionary(19 unique tokens: ['cute', 'kitten', 'purr', 'watch', 'stark']...)\n"
     ]
    }
   ],
   "source": [
    "#Make Dictionary \n",
    "dictionary = corpora.Dictionary(texts)\n",
    "#dictionary.save(('dovel1.dict'))  # store the dictionary, for future reference\n",
    "print(dictionary.token2id)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Matrix Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(0, 1), (2, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)],\n",
       " [(0, 1), (1, 1), (10, 1), (11, 1), (12, 1), (13, 1)],\n",
       " [(8, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "#corpora.MmCorpus.serialize('dovel1.mm', corpus)  # store to disk, for later use\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V Model Initialization \n",
    "#In spaCy there is an already initialized w2v model pre-trained on Stanford's GloVe https://nlp.stanford.edu/projects/glove/\n",
    "    #\"The default English model installs vectors for one million vocabulary entries, \n",
    "    #using the 300-dimensional vectors trained on the Common Crawl corpus using the GloVe algorithm. \n",
    "    #The GloVe common crawl vectors have become a de facto standard for practical NLP.\"\n",
    "#https://spacy.io/docs/usage/word-vectors-similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy Token:  cute\n",
      "Vector Size:  300\n",
      "[-0.35642001 -0.12153    -0.60569    -0.062242   -0.12673    -0.02612\n",
      " -0.058334   -0.59749001  0.080791    1.00230002 -0.30669999 -0.49897999\n",
      " -0.16244    -0.31716001 -0.38573     0.03942    -0.26468     1.22529995\n",
      "  0.19279     0.005312   -0.12395    -0.30101001 -0.17156    -0.42899001\n",
      "  0.034108    0.43832999  0.18667001 -0.73627001  0.25948     0.031607\n",
      " -0.39974001 -0.16317999  0.17473     0.33381999  0.24716    -0.57972997\n",
      " -0.020651   -0.041078   -0.49728999 -0.10925    -0.43551001 -0.021357\n",
      " -0.13062    -0.21269999  0.35229999 -0.25628999 -0.62704998  0.073671\n",
      "  0.26864001 -0.45034   ] ...\n",
      "\n",
      "Spacy Token:  .\n",
      "Vector Size:  300\n",
      "[ 0.012001    0.20750999 -0.12578    -0.59324998  0.12525     0.15975\n",
      "  0.13748001 -0.33157    -0.13694     1.78929996 -0.47093999  0.70433998\n",
      "  0.26673001 -0.089961   -0.18167999  0.067226    0.053347    1.55949998\n",
      " -0.25409999  0.038413   -0.01409     0.056774    0.023434    0.024042\n",
      "  0.31703001  0.19024999 -0.37505001  0.035603    0.1181      0.012032\n",
      " -0.037566   -0.50459999 -0.049261    0.092351    0.11031    -0.073062\n",
      "  0.33994001  0.28239     0.13413     0.070128   -0.022099   -0.28103\n",
      "  0.49607    -0.48693001 -0.090964   -0.1538     -0.38011    -0.014228\n",
      " -0.19392    -0.11068   ] ...\n"
     ]
    }
   ],
   "source": [
    "cute_vector = docs[1].vector\n",
    "print('Spacy Token: ', docs[1])\n",
    "print('Vector Size: ', len(cute_vector))\n",
    "print(cute_vector[0:50], '...')\n",
    "\n",
    "print()\n",
    "\n",
    "period_vector = docs[20].vector\n",
    "print('Spacy Token: ', docs[20])\n",
    "print('Vector Size: ', len(period_vector))\n",
    "print(period_vector[0:50], '...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cute kitten purred and watched the Stark girl.\n",
      "Vector Length of  300\n",
      "[-0.0394899  -0.0187946  -0.2313281  -0.07501449 -0.0034923  -0.03543136\n",
      " -0.08365459 -0.1366701   0.07988711  1.59997201 -0.22350159 -0.01495151\n",
      "  0.01841    -0.1657521  -0.14396301  0.07315359 -0.0264913   0.67474192\n",
      " -0.152256   -0.06521721 -0.04318    -0.16186132 -0.12671219 -0.10123821\n",
      "  0.0410289   0.0970646  -0.112487   -0.14183018  0.01335313 -0.04647293\n",
      " -0.14982264  0.0205042  -0.0090121   0.168327    0.182576   -0.17904079\n",
      "  0.0069503  -0.05956352 -0.15230086 -0.0496251   0.01015183  0.0113903\n",
      "  0.00332989 -0.16249254  0.0382682  -0.05392995 -0.27333999  0.06541368\n",
      "  0.0911456  -0.227585  ] ...\n",
      "\n",
      "After losing interest the cute furry cat purred and meowed.\n",
      "Vector Length of  300\n",
      "[-0.07320991  0.11364457 -0.18259937 -0.04985264 -0.018801   -0.03465935\n",
      " -0.037993   -0.12700583  0.02468536  1.65511811 -0.21201697  0.05384245\n",
      " -0.07783545 -0.07012409 -0.05808636 -0.06650855 -0.05374527  0.72631359\n",
      " -0.14617108 -0.06922891 -0.07182118 -0.06767427 -0.11332254 -0.116397\n",
      "  0.10679228  0.05630463 -0.08012091 -0.10325181  0.01807976  0.022002\n",
      " -0.15857078 -0.017925    0.01034355  0.08475245  0.14046091 -0.08843163\n",
      "  0.05284046 -0.07485914 -0.0205258  -0.04394236  0.02954002  0.04570173\n",
      "  0.07407293 -0.05270151  0.04326145 -0.00346945 -0.28251508  0.0603629\n",
      " -0.01572791 -0.08664572] ...\n"
     ]
    }
   ],
   "source": [
    "s1_spcy = docs[0:10]\n",
    "s1_vect = s1_spcy.vector\n",
    "s2_spcy = docs[10:21]\n",
    "s2_vect = s2_spcy.vector\n",
    "s3_spcy = docs[21:33]\n",
    "s3_vect = s3_spcy.vector\n",
    "s4_spcy = docs[33:43]\n",
    "s4_vect = s4_spcy.vector\n",
    "\n",
    "s1 = corpus[0]\n",
    "s2 = corpus[1]\n",
    "s3 = corpus[2]\n",
    "s4 = corpus[3]\n",
    "\n",
    "print(s1_spcy)\n",
    "print('Vector Length of ', len(s1_vect))\n",
    "print(s1_vect[0:50], '...')\n",
    "\n",
    "print()\n",
    "\n",
    "print(s2_spcy)\n",
    "print('Vector Length of ', len(s2_vect))\n",
    "print(s2_vect[0:50], '...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cute kitten purred and watched the Stark girl. After losing interest the cute furry cat purred and meowed. Sly yet silent, the cute kitten meowed and she noticed. The loud furry dog ran and bit at air.\n",
      "[ -2.96052452e-02   1.07662223e-01  -1.49132133e-01  -7.46969581e-02\n",
      "   1.32708149e-02   3.17049772e-02  -1.09451404e-02  -1.61642089e-01\n",
      "   2.65648309e-02   1.74241495e+00  -1.46555364e-01   5.43590356e-03\n",
      "  -2.56856922e-02  -1.58875853e-01  -1.62996352e-01   2.48137470e-02\n",
      "  -3.87500040e-02   7.81989813e-01  -2.00948134e-01  -7.90675804e-02\n",
      "  -5.39194196e-02  -6.40327632e-02  -5.70502989e-02  -1.32878065e-01\n",
      "   5.21605499e-02   5.05217910e-02  -1.22933485e-01  -1.20797276e-01\n",
      "   7.05222115e-02  -8.14056993e-02  -1.35169148e-01   1.08062522e-03\n",
      "  -5.00328802e-02   1.31003201e-01   1.24342784e-01  -1.46289453e-01\n",
      "   1.29621802e-03  -3.99797671e-02  -1.01229399e-01  -3.95646989e-02\n",
      "   5.10285832e-02   2.97673959e-02   1.50560727e-02  -1.08856298e-01\n",
      "   9.05850902e-02  -1.38813816e-02  -2.71683395e-01  -2.40068045e-02\n",
      "   1.05061131e-02  -1.12254865e-01]\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "#Same can be done at the document level\n",
    "print(docs)\n",
    "docs_vector = docs.vector\n",
    "print(docs_vector[0:50])\n",
    "print(len(docs_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf['Sentence'] = [raw1, raw2, raw3, raw4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Tokenization Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf['Tokens'] = [texts[0], texts[1], texts[2],texts[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Corpus Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf['Corpus'] = [s1, s2, s3, s4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Sen2Vec Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdf['Sen2Vec'] = [s1_vect, s2_vect, s3_vect, s4_vect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Sen2Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cute kitten purred and watched the Stark g...</td>\n",
       "      <td>[cute, kitten, purr, watch, stark, girl]</td>\n",
       "      <td>[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]</td>\n",
       "      <td>[-0.0394899, -0.0187946, -0.231328, -0.0750145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After losing interest the cute furry cat purr...</td>\n",
       "      <td>[lose, interest, cute, furry, cat, purr, meow]</td>\n",
       "      <td>[(0, 1), (2, 1), (6, 1), (7, 1), (8, 1), (9, 1...</td>\n",
       "      <td>[-0.0732099, 0.113645, -0.182599, -0.0498526, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sly yet silent, the cute kitten meowed and sh...</td>\n",
       "      <td>[sly, silent, cute, kitten, meow, notice]</td>\n",
       "      <td>[(0, 1), (1, 1), (10, 1), (11, 1), (12, 1), (1...</td>\n",
       "      <td>[0.00436454, 0.100187, -0.162217, -0.0844011, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The loud furry dog ran and bit at air.</td>\n",
       "      <td>[loud, furry, dog, run, bit, air]</td>\n",
       "      <td>[(8, 1), (14, 1), (15, 1), (16, 1), (17, 1), (...</td>\n",
       "      <td>[-0.0125192, 0.236509, -0.0144205, -0.0900632,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  The cute kitten purred and watched the Stark g...   \n",
       "1   After losing interest the cute furry cat purr...   \n",
       "2   Sly yet silent, the cute kitten meowed and sh...   \n",
       "3             The loud furry dog ran and bit at air.   \n",
       "\n",
       "                                           Tokens  \\\n",
       "0        [cute, kitten, purr, watch, stark, girl]   \n",
       "1  [lose, interest, cute, furry, cat, purr, meow]   \n",
       "2       [sly, silent, cute, kitten, meow, notice]   \n",
       "3               [loud, furry, dog, run, bit, air]   \n",
       "\n",
       "                                              Corpus  \\\n",
       "0   [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]   \n",
       "1  [(0, 1), (2, 1), (6, 1), (7, 1), (8, 1), (9, 1...   \n",
       "2  [(0, 1), (1, 1), (10, 1), (11, 1), (12, 1), (1...   \n",
       "3  [(8, 1), (14, 1), (15, 1), (16, 1), (17, 1), (...   \n",
       "\n",
       "                                             Sen2Vec  \n",
       "0  [-0.0394899, -0.0187946, -0.231328, -0.0750145...  \n",
       "1  [-0.0732099, 0.113645, -0.182599, -0.0498526, ...  \n",
       "2  [0.00436454, 0.100187, -0.162217, -0.0844011, ...  \n",
       "3  [-0.0125192, 0.236509, -0.0144205, -0.0900632,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
